# naive_bayes_filter
Used the Naive Bayes algorithm to train a spam classifier with a dataset of emails (bag of words model)

The bag of words model in NLP is a unigram model which considers a text to be represented as a bag of independent words. We count frequency of words, not position. Each email consists of a group of words. Using Bayes theorem, we compute the probability that the label of an email (Y) should be ham (Y=ham) given the words in the email.

`python3 grade.py`

#TODO: fix the grading file
